{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ai-deen/DS605-Sign-Lanaguage-Translation-Project/blob/main/DS605_project_SLT_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5a3i8YP8MRC"
      },
      "outputs": [],
      "source": [
        "# https://github.com/kayoyin/transformer-slt\n",
        "        print(\"START\")\n",
        "        print(type(self._batch_index))\n",
        "        # Resolve beam origin and map to batch index flat representation.\n",
        "        #torch.div(self.topk_ids.float(), vocab_size, out=self._batch_index)\n",
        "        self._batch_index = self.topk_ids // vocab_size\n",
        "        print(\"ENDED\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftlD8sxR9zLR",
        "outputId": "43675fc9-d817-451c-9e29-99b020812218"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: line 1: virtualenv: command not found\n",
            "/bin/bash: line 1: venv/bin/activate: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!virtualenv --python=python3 venv\n",
        "!source venv/bin/activate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EuSsPBOl8UZq",
        "outputId": "538779cc-6a15-44e9-9a67-15e89129ae55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'transformer-slt'...\n",
            "remote: Enumerating objects: 262, done.\u001b[K\n",
            "remote: Counting objects: 100% (262/262), done.\u001b[K\n",
            "remote: Compressing objects: 100% (237/237), done.\u001b[K\n",
            "remote: Total 262 (delta 64), reused 203 (delta 22), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (262/262), 7.32 MiB | 11.37 MiB/s, done.\n",
            "Resolving deltas: 100% (64/64), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/kayoyin/transformer-slt.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PYswJmC8Z2K",
        "outputId": "3d0c5dc7-ef29-4f88-eaa1-2cc40c927737"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/transformer-slt\n"
          ]
        }
      ],
      "source": [
        "%cd transformer-slt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIbD3lva8e6z",
        "outputId": "ccf387b8-e3b3-4956-8ee7-6738c4c36ad3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->-r requirements.txt (line 1)) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->-r requirements.txt (line 1)) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->-r requirements.txt (line 1)) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->-r requirements.txt (line 1)) (4.66.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jha9cxx8jwO",
        "outputId": "fb3b7d97-b2c9-4ed2-9a84-ebc8dbb204a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running install\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` and ``easy_install``.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://github.com/pypa/setuptools/issues/917 for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating OpenNMT_py.egg-info\n",
            "writing OpenNMT_py.egg-info/PKG-INFO\n",
            "writing dependency_links to OpenNMT_py.egg-info/dependency_links.txt\n",
            "writing entry points to OpenNMT_py.egg-info/entry_points.txt\n",
            "writing requirements to OpenNMT_py.egg-info/requires.txt\n",
            "writing top-level names to OpenNMT_py.egg-info/top_level.txt\n",
            "writing manifest file 'OpenNMT_py.egg-info/SOURCES.txt'\n",
            "reading manifest file 'OpenNMT_py.egg-info/SOURCES.txt'\n",
            "adding license file 'LICENSE.md'\n",
            "writing manifest file 'OpenNMT_py.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/onmt\n",
            "copying onmt/opts.py -> build/lib/onmt\n",
            "copying onmt/train_single.py -> build/lib/onmt\n",
            "copying onmt/model_builder.py -> build/lib/onmt\n",
            "copying onmt/trainer.py -> build/lib/onmt\n",
            "copying onmt/__init__.py -> build/lib/onmt\n",
            "creating build/lib/onmt/inputters\n",
            "copying onmt/inputters/text_dataset.py -> build/lib/onmt/inputters\n",
            "copying onmt/inputters/dataset_base.py -> build/lib/onmt/inputters\n",
            "copying onmt/inputters/datareader_base.py -> build/lib/onmt/inputters\n",
            "copying onmt/inputters/inputter.py -> build/lib/onmt/inputters\n",
            "copying onmt/inputters/__init__.py -> build/lib/onmt/inputters\n",
            "creating build/lib/onmt/models\n",
            "copying onmt/models/model.py -> build/lib/onmt/models\n",
            "copying onmt/models/model_saver.py -> build/lib/onmt/models\n",
            "copying onmt/models/stacked_rnn.py -> build/lib/onmt/models\n",
            "copying onmt/models/sru.py -> build/lib/onmt/models\n",
            "copying onmt/models/__init__.py -> build/lib/onmt/models\n",
            "creating build/lib/onmt/utils\n",
            "copying onmt/utils/statistics.py -> build/lib/onmt/utils\n",
            "copying onmt/utils/distributed.py -> build/lib/onmt/utils\n",
            "copying onmt/utils/misc.py -> build/lib/onmt/utils\n",
            "copying onmt/utils/logging.py -> build/lib/onmt/utils\n",
            "copying onmt/utils/alignment.py -> build/lib/onmt/utils\n",
            "copying onmt/utils/optimizers.py -> build/lib/onmt/utils\n",
            "copying onmt/utils/loss.py -> build/lib/onmt/utils\n",
            "copying onmt/utils/parse.py -> build/lib/onmt/utils\n",
            "copying onmt/utils/rnn_factory.py -> build/lib/onmt/utils\n",
            "copying onmt/utils/earlystopping.py -> build/lib/onmt/utils\n",
            "copying onmt/utils/report_manager.py -> build/lib/onmt/utils\n",
            "copying onmt/utils/__init__.py -> build/lib/onmt/utils\n",
            "creating build/lib/onmt/translate\n",
            "copying onmt/translate/greedy_search.py -> build/lib/onmt/translate\n",
            "copying onmt/translate/process_zh.py -> build/lib/onmt/translate\n",
            "copying onmt/translate/decode_strategy.py -> build/lib/onmt/translate\n",
            "copying onmt/translate/translator.py -> build/lib/onmt/translate\n",
            "copying onmt/translate/translation_server.py -> build/lib/onmt/translate\n",
            "copying onmt/translate/beam_search.py -> build/lib/onmt/translate\n",
            "copying onmt/translate/translation.py -> build/lib/onmt/translate\n",
            "copying onmt/translate/penalties.py -> build/lib/onmt/translate\n",
            "copying onmt/translate/__init__.py -> build/lib/onmt/translate\n",
            "creating build/lib/onmt/encoders\n",
            "copying onmt/encoders/transformer.py -> build/lib/onmt/encoders\n",
            "copying onmt/encoders/encoder.py -> build/lib/onmt/encoders\n",
            "copying onmt/encoders/rnn_encoder.py -> build/lib/onmt/encoders\n",
            "copying onmt/encoders/mean_encoder.py -> build/lib/onmt/encoders\n",
            "copying onmt/encoders/__init__.py -> build/lib/onmt/encoders\n",
            "creating build/lib/onmt/modules\n",
            "copying onmt/modules/embeddings.py -> build/lib/onmt/modules\n",
            "copying onmt/modules/util_class.py -> build/lib/onmt/modules\n",
            "copying onmt/modules/average_attn.py -> build/lib/onmt/modules\n",
            "copying onmt/modules/sparse_activations.py -> build/lib/onmt/modules\n",
            "copying onmt/modules/global_attention.py -> build/lib/onmt/modules\n",
            "copying onmt/modules/weight_norm.py -> build/lib/onmt/modules\n",
            "copying onmt/modules/multi_headed_attn.py -> build/lib/onmt/modules\n",
            "copying onmt/modules/sparse_losses.py -> build/lib/onmt/modules\n",
            "copying onmt/modules/position_ffn.py -> build/lib/onmt/modules\n",
            "copying onmt/modules/conv_multi_step_attention.py -> build/lib/onmt/modules\n",
            "copying onmt/modules/copy_generator.py -> build/lib/onmt/modules\n",
            "copying onmt/modules/gate.py -> build/lib/onmt/modules\n",
            "copying onmt/modules/structured_attention.py -> build/lib/onmt/modules\n",
            "copying onmt/modules/__init__.py -> build/lib/onmt/modules\n",
            "creating build/lib/onmt/bin\n",
            "copying onmt/bin/release_model.py -> build/lib/onmt/bin\n",
            "copying onmt/bin/server.py -> build/lib/onmt/bin\n",
            "copying onmt/bin/average_models.py -> build/lib/onmt/bin\n",
            "copying onmt/bin/translate.py -> build/lib/onmt/bin\n",
            "copying onmt/bin/preprocess.py -> build/lib/onmt/bin\n",
            "copying onmt/bin/train.py -> build/lib/onmt/bin\n",
            "copying onmt/bin/__init__.py -> build/lib/onmt/bin\n",
            "creating build/lib/onmt/decoders\n",
            "copying onmt/decoders/transformer.py -> build/lib/onmt/decoders\n",
            "copying onmt/decoders/decoder.py -> build/lib/onmt/decoders\n",
            "copying onmt/decoders/ensemble.py -> build/lib/onmt/decoders\n",
            "copying onmt/decoders/__init__.py -> build/lib/onmt/decoders\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/onmt\n",
            "copying build/lib/onmt/opts.py -> build/bdist.linux-x86_64/egg/onmt\n",
            "copying build/lib/onmt/train_single.py -> build/bdist.linux-x86_64/egg/onmt\n",
            "copying build/lib/onmt/model_builder.py -> build/bdist.linux-x86_64/egg/onmt\n",
            "creating build/bdist.linux-x86_64/egg/onmt/inputters\n",
            "copying build/lib/onmt/inputters/text_dataset.py -> build/bdist.linux-x86_64/egg/onmt/inputters\n",
            "copying build/lib/onmt/inputters/dataset_base.py -> build/bdist.linux-x86_64/egg/onmt/inputters\n",
            "copying build/lib/onmt/inputters/datareader_base.py -> build/bdist.linux-x86_64/egg/onmt/inputters\n",
            "copying build/lib/onmt/inputters/inputter.py -> build/bdist.linux-x86_64/egg/onmt/inputters\n",
            "copying build/lib/onmt/inputters/__init__.py -> build/bdist.linux-x86_64/egg/onmt/inputters\n",
            "creating build/bdist.linux-x86_64/egg/onmt/models\n",
            "copying build/lib/onmt/models/model.py -> build/bdist.linux-x86_64/egg/onmt/models\n",
            "copying build/lib/onmt/models/model_saver.py -> build/bdist.linux-x86_64/egg/onmt/models\n",
            "copying build/lib/onmt/models/stacked_rnn.py -> build/bdist.linux-x86_64/egg/onmt/models\n",
            "copying build/lib/onmt/models/sru.py -> build/bdist.linux-x86_64/egg/onmt/models\n",
            "copying build/lib/onmt/models/__init__.py -> build/bdist.linux-x86_64/egg/onmt/models\n",
            "creating build/bdist.linux-x86_64/egg/onmt/utils\n",
            "copying build/lib/onmt/utils/statistics.py -> build/bdist.linux-x86_64/egg/onmt/utils\n",
            "copying build/lib/onmt/utils/distributed.py -> build/bdist.linux-x86_64/egg/onmt/utils\n",
            "copying build/lib/onmt/utils/misc.py -> build/bdist.linux-x86_64/egg/onmt/utils\n",
            "copying build/lib/onmt/utils/logging.py -> build/bdist.linux-x86_64/egg/onmt/utils\n",
            "copying build/lib/onmt/utils/alignment.py -> build/bdist.linux-x86_64/egg/onmt/utils\n",
            "copying build/lib/onmt/utils/optimizers.py -> build/bdist.linux-x86_64/egg/onmt/utils\n",
            "copying build/lib/onmt/utils/loss.py -> build/bdist.linux-x86_64/egg/onmt/utils\n",
            "copying build/lib/onmt/utils/parse.py -> build/bdist.linux-x86_64/egg/onmt/utils\n",
            "copying build/lib/onmt/utils/rnn_factory.py -> build/bdist.linux-x86_64/egg/onmt/utils\n",
            "copying build/lib/onmt/utils/earlystopping.py -> build/bdist.linux-x86_64/egg/onmt/utils\n",
            "copying build/lib/onmt/utils/report_manager.py -> build/bdist.linux-x86_64/egg/onmt/utils\n",
            "copying build/lib/onmt/utils/__init__.py -> build/bdist.linux-x86_64/egg/onmt/utils\n",
            "copying build/lib/onmt/trainer.py -> build/bdist.linux-x86_64/egg/onmt\n",
            "creating build/bdist.linux-x86_64/egg/onmt/translate\n",
            "copying build/lib/onmt/translate/greedy_search.py -> build/bdist.linux-x86_64/egg/onmt/translate\n",
            "copying build/lib/onmt/translate/process_zh.py -> build/bdist.linux-x86_64/egg/onmt/translate\n",
            "copying build/lib/onmt/translate/decode_strategy.py -> build/bdist.linux-x86_64/egg/onmt/translate\n",
            "copying build/lib/onmt/translate/translator.py -> build/bdist.linux-x86_64/egg/onmt/translate\n",
            "copying build/lib/onmt/translate/translation_server.py -> build/bdist.linux-x86_64/egg/onmt/translate\n",
            "copying build/lib/onmt/translate/beam_search.py -> build/bdist.linux-x86_64/egg/onmt/translate\n",
            "copying build/lib/onmt/translate/translation.py -> build/bdist.linux-x86_64/egg/onmt/translate\n",
            "copying build/lib/onmt/translate/penalties.py -> build/bdist.linux-x86_64/egg/onmt/translate\n",
            "copying build/lib/onmt/translate/__init__.py -> build/bdist.linux-x86_64/egg/onmt/translate\n",
            "creating build/bdist.linux-x86_64/egg/onmt/encoders\n",
            "copying build/lib/onmt/encoders/transformer.py -> build/bdist.linux-x86_64/egg/onmt/encoders\n",
            "copying build/lib/onmt/encoders/encoder.py -> build/bdist.linux-x86_64/egg/onmt/encoders\n",
            "copying build/lib/onmt/encoders/rnn_encoder.py -> build/bdist.linux-x86_64/egg/onmt/encoders\n",
            "copying build/lib/onmt/encoders/mean_encoder.py -> build/bdist.linux-x86_64/egg/onmt/encoders\n",
            "copying build/lib/onmt/encoders/__init__.py -> build/bdist.linux-x86_64/egg/onmt/encoders\n",
            "creating build/bdist.linux-x86_64/egg/onmt/modules\n",
            "copying build/lib/onmt/modules/embeddings.py -> build/bdist.linux-x86_64/egg/onmt/modules\n",
            "copying build/lib/onmt/modules/util_class.py -> build/bdist.linux-x86_64/egg/onmt/modules\n",
            "copying build/lib/onmt/modules/average_attn.py -> build/bdist.linux-x86_64/egg/onmt/modules\n",
            "copying build/lib/onmt/modules/sparse_activations.py -> build/bdist.linux-x86_64/egg/onmt/modules\n",
            "copying build/lib/onmt/modules/global_attention.py -> build/bdist.linux-x86_64/egg/onmt/modules\n",
            "copying build/lib/onmt/modules/weight_norm.py -> build/bdist.linux-x86_64/egg/onmt/modules\n",
            "copying build/lib/onmt/modules/multi_headed_attn.py -> build/bdist.linux-x86_64/egg/onmt/modules\n",
            "copying build/lib/onmt/modules/sparse_losses.py -> build/bdist.linux-x86_64/egg/onmt/modules\n",
            "copying build/lib/onmt/modules/position_ffn.py -> build/bdist.linux-x86_64/egg/onmt/modules\n",
            "copying build/lib/onmt/modules/conv_multi_step_attention.py -> build/bdist.linux-x86_64/egg/onmt/modules\n",
            "copying build/lib/onmt/modules/copy_generator.py -> build/bdist.linux-x86_64/egg/onmt/modules\n",
            "copying build/lib/onmt/modules/gate.py -> build/bdist.linux-x86_64/egg/onmt/modules\n",
            "copying build/lib/onmt/modules/structured_attention.py -> build/bdist.linux-x86_64/egg/onmt/modules\n",
            "copying build/lib/onmt/modules/__init__.py -> build/bdist.linux-x86_64/egg/onmt/modules\n",
            "creating build/bdist.linux-x86_64/egg/onmt/bin\n",
            "copying build/lib/onmt/bin/release_model.py -> build/bdist.linux-x86_64/egg/onmt/bin\n",
            "copying build/lib/onmt/bin/server.py -> build/bdist.linux-x86_64/egg/onmt/bin\n",
            "copying build/lib/onmt/bin/average_models.py -> build/bdist.linux-x86_64/egg/onmt/bin\n",
            "copying build/lib/onmt/bin/translate.py -> build/bdist.linux-x86_64/egg/onmt/bin\n",
            "copying build/lib/onmt/bin/preprocess.py -> build/bdist.linux-x86_64/egg/onmt/bin\n",
            "copying build/lib/onmt/bin/train.py -> build/bdist.linux-x86_64/egg/onmt/bin\n",
            "copying build/lib/onmt/bin/__init__.py -> build/bdist.linux-x86_64/egg/onmt/bin\n",
            "creating build/bdist.linux-x86_64/egg/onmt/decoders\n",
            "copying build/lib/onmt/decoders/transformer.py -> build/bdist.linux-x86_64/egg/onmt/decoders\n",
            "copying build/lib/onmt/decoders/decoder.py -> build/bdist.linux-x86_64/egg/onmt/decoders\n",
            "copying build/lib/onmt/decoders/ensemble.py -> build/bdist.linux-x86_64/egg/onmt/decoders\n",
            "copying build/lib/onmt/decoders/__init__.py -> build/bdist.linux-x86_64/egg/onmt/decoders\n",
            "copying build/lib/onmt/__init__.py -> build/bdist.linux-x86_64/egg/onmt\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/opts.py to opts.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/train_single.py to train_single.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/model_builder.py to model_builder.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/inputters/text_dataset.py to text_dataset.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/inputters/dataset_base.py to dataset_base.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/inputters/datareader_base.py to datareader_base.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/inputters/inputter.py to inputter.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/inputters/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/models/model.py to model.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/models/model_saver.py to model_saver.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/models/stacked_rnn.py to stacked_rnn.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/models/sru.py to sru.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/models/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/utils/statistics.py to statistics.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/utils/distributed.py to distributed.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/utils/misc.py to misc.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/utils/logging.py to logging.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/utils/alignment.py to alignment.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/utils/optimizers.py to optimizers.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/utils/loss.py to loss.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/utils/parse.py to parse.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/utils/rnn_factory.py to rnn_factory.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/utils/earlystopping.py to earlystopping.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/utils/report_manager.py to report_manager.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/utils/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/trainer.py to trainer.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/translate/greedy_search.py to greedy_search.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/translate/process_zh.py to process_zh.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/translate/decode_strategy.py to decode_strategy.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/translate/translator.py to translator.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/translate/translation_server.py to translation_server.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/translate/beam_search.py to beam_search.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/translate/translation.py to translation.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/translate/penalties.py to penalties.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/translate/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/encoders/transformer.py to transformer.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/encoders/encoder.py to encoder.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/encoders/rnn_encoder.py to rnn_encoder.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/encoders/mean_encoder.py to mean_encoder.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/encoders/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/modules/embeddings.py to embeddings.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/modules/util_class.py to util_class.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/modules/average_attn.py to average_attn.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/modules/sparse_activations.py to sparse_activations.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/modules/global_attention.py to global_attention.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/modules/weight_norm.py to weight_norm.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/modules/multi_headed_attn.py to multi_headed_attn.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/modules/sparse_losses.py to sparse_losses.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/modules/position_ffn.py to position_ffn.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/modules/conv_multi_step_attention.py to conv_multi_step_attention.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/modules/copy_generator.py to copy_generator.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/modules/gate.py to gate.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/modules/structured_attention.py to structured_attention.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/modules/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/bin/release_model.py to release_model.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/bin/server.py to server.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/bin/average_models.py to average_models.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/bin/translate.py to translate.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/bin/preprocess.py to preprocess.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/bin/train.py to train.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/bin/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/decoders/transformer.py to transformer.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/decoders/decoder.py to decoder.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/decoders/ensemble.py to ensemble.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/decoders/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/__init__.py to __init__.cpython-310.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying OpenNMT_py.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying OpenNMT_py.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying OpenNMT_py.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying OpenNMT_py.egg-info/entry_points.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying OpenNMT_py.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying OpenNMT_py.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating dist\n",
            "creating 'dist/OpenNMT_py-1.0.0-py3.10.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing OpenNMT_py-1.0.0-py3.10.egg\n",
            "Copying OpenNMT_py-1.0.0-py3.10.egg to /usr/local/lib/python3.10/dist-packages\n",
            "Adding OpenNMT-py 1.0.0 to easy-install.pth file\n",
            "Installing onmt_average_models script to /usr/local/bin\n",
            "Installing onmt_preprocess script to /usr/local/bin\n",
            "Installing onmt_release_model script to /usr/local/bin\n",
            "Installing onmt_server script to /usr/local/bin\n",
            "Installing onmt_train script to /usr/local/bin\n",
            "Installing onmt_translate script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/OpenNMT_py-1.0.0-py3.10.egg\n",
            "Processing dependencies for OpenNMT-py==1.0.0\n",
            "Searching for pyonmttok==1.*\n",
            "Reading https://pypi.org/simple/pyonmttok/\n",
            "Downloading https://files.pythonhosted.org/packages/09/91/bc1a1e7d38913b0eca17d2dcef3606ef2f65d57a4971ad64af8607c78aaf/pyonmttok-1.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl#sha256=0cdfc6cebbf4921fcfcb4e76388142c777c025d014bd79d9a7858bba54b04129\n",
            "Best match: pyonmttok 1.37.1\n",
            "Processing pyonmttok-1.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
            "Installing pyonmttok-1.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl to /usr/local/lib/python3.10/dist-packages\n",
            "Adding pyonmttok 1.37.1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/pyonmttok-1.37.1-py3.10-linux-x86_64.egg\n",
            "Searching for waitress\n",
            "Reading https://pypi.org/simple/waitress/\n",
            "Downloading https://files.pythonhosted.org/packages/58/6a/b4b5c582e04e837e4422cab6ec9de7fc10ca7ad7f4e370bb89d280d39552/waitress-2.1.2-py3-none-any.whl#sha256=7500c9625927c8ec60f54377d590f67b30c8e70ef4b8894214ac6e4cad233d2a\n",
            "Best match: waitress 2.1.2\n",
            "Processing waitress-2.1.2-py3-none-any.whl\n",
            "Installing waitress-2.1.2-py3-none-any.whl to /usr/local/lib/python3.10/dist-packages\n",
            "Adding waitress 2.1.2 to easy-install.pth file\n",
            "Installing waitress-serve script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/waitress-2.1.2-py3.10.egg\n",
            "Searching for configargparse\n",
            "Reading https://pypi.org/simple/configargparse/\n",
            "Downloading https://files.pythonhosted.org/packages/6f/b3/b4ac838711fd74a2b4e6f746703cf9dd2cf5462d17dac07e349234e21b97/ConfigArgParse-1.7-py3-none-any.whl#sha256=d249da6591465c6c26df64a9f73d2536e743be2f244eb3ebe61114af2f94f86b\n",
            "Best match: ConfigArgParse 1.7\n",
            "Processing ConfigArgParse-1.7-py3-none-any.whl\n",
            "Installing ConfigArgParse-1.7-py3-none-any.whl to /usr/local/lib/python3.10/dist-packages\n",
            "Adding ConfigArgParse 1.7 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/ConfigArgParse-1.7-py3.10.egg\n",
            "Searching for torchtext==0.4.0\n",
            "Reading https://pypi.org/simple/torchtext/\n",
            "Downloading https://files.pythonhosted.org/packages/43/94/929d6bd236a4fb5c435982a7eb9730b78dcd8659acf328fd2ef9de85f483/torchtext-0.4.0-py3-none-any.whl#sha256=094520d9cd0af6a05368d9023fdc91dc038232bd9d128c7b548ec2200dba53ec\n",
            "Best match: torchtext 0.4.0\n",
            "Processing torchtext-0.4.0-py3-none-any.whl\n",
            "Installing torchtext-0.4.0-py3-none-any.whl to /usr/local/lib/python3.10/dist-packages\n",
            "Adding torchtext 0.4.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/torchtext-0.4.0-py3.10.egg\n",
            "Searching for tqdm~=4.30.0\n",
            "Reading https://pypi.org/simple/tqdm/\n",
            "Downloading https://files.pythonhosted.org/packages/76/4c/103a4d3415dafc1ddfe6a6624333971756e2d3dd8c6dc0f520152855f040/tqdm-4.30.0-py2.py3-none-any.whl#sha256=13f018038711256ed27aae118a80d63929588e90f00d072a0f4eb7aa3333b4dc\n",
            "Best match: tqdm 4.30.0\n",
            "Processing tqdm-4.30.0-py2.py3-none-any.whl\n",
            "Installing tqdm-4.30.0-py2.py3-none-any.whl to /usr/local/lib/python3.10/dist-packages\n",
            "Adding tqdm 4.30.0 to easy-install.pth file\n",
            "Installing tqdm script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/tqdm-4.30.0-py3.10.egg\n",
            "Searching for Flask==2.2.5\n",
            "Best match: Flask 2.2.5\n",
            "Adding Flask 2.2.5 to easy-install.pth file\n",
            "Installing flask script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for tensorboard==2.14.1\n",
            "Best match: tensorboard 2.14.1\n",
            "Adding tensorboard 2.14.1 to easy-install.pth file\n",
            "Installing tensorboard script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for future==0.18.3\n",
            "Best match: future 0.18.3\n",
            "Adding future 0.18.3 to easy-install.pth file\n",
            "Installing futurize script to /usr/local/bin\n",
            "Installing pasteurize script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for torch==2.1.0+cu118\n",
            "Best match: torch 2.1.0+cu118\n",
            "Adding torch 2.1.0+cu118 to easy-install.pth file\n",
            "Installing convert-caffe2-to-onnx script to /usr/local/bin\n",
            "Installing convert-onnx-to-caffe2 script to /usr/local/bin\n",
            "Installing torchrun script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for six==1.16.0\n",
            "Best match: six 1.16.0\n",
            "Adding six 1.16.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for click==8.1.7\n",
            "Best match: click 8.1.7\n",
            "Adding click 8.1.7 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for itsdangerous==2.1.2\n",
            "Best match: itsdangerous 2.1.2\n",
            "Adding itsdangerous 2.1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for Jinja2==3.1.2\n",
            "Best match: Jinja2 3.1.2\n",
            "Adding Jinja2 3.1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for werkzeug==3.0.1\n",
            "Best match: werkzeug 3.0.1\n",
            "Adding werkzeug 3.0.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for tensorboard-data-server==0.7.2\n",
            "Best match: tensorboard-data-server 0.7.2\n",
            "Adding tensorboard-data-server 0.7.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for setuptools==67.7.2\n",
            "Best match: setuptools 67.7.2\n",
            "Adding setuptools 67.7.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for requests==2.31.0\n",
            "Best match: requests 2.31.0\n",
            "Adding requests 2.31.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for protobuf==3.20.3\n",
            "Best match: protobuf 3.20.3\n",
            "Adding protobuf 3.20.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for numpy==1.23.5\n",
            "Best match: numpy 1.23.5\n",
            "Adding numpy 1.23.5 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.10 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for Markdown==3.5.1\n",
            "Best match: Markdown 3.5.1\n",
            "Adding Markdown 3.5.1 to easy-install.pth file\n",
            "Installing markdown_py script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for google-auth-oauthlib==1.0.0\n",
            "Best match: google-auth-oauthlib 1.0.0\n",
            "Adding google-auth-oauthlib 1.0.0 to easy-install.pth file\n",
            "Installing google-oauthlib-tool script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for google-auth==2.17.3\n",
            "Best match: google-auth 2.17.3\n",
            "Adding google-auth 2.17.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for grpcio==1.59.2\n",
            "Best match: grpcio 1.59.2\n",
            "Adding grpcio 1.59.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for absl-py==1.4.0\n",
            "Best match: absl-py 1.4.0\n",
            "Adding absl-py 1.4.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for triton==2.1.0\n",
            "Best match: triton 2.1.0\n",
            "Adding triton 2.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for fsspec==2023.6.0\n",
            "Best match: fsspec 2023.6.0\n",
            "Adding fsspec 2023.6.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for networkx==3.2.1\n",
            "Best match: networkx 3.2.1\n",
            "Adding networkx 3.2.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for sympy==1.12\n",
            "Best match: sympy 1.12\n",
            "Adding sympy 1.12 to easy-install.pth file\n",
            "Installing isympy script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for typing-extensions==4.5.0\n",
            "Best match: typing-extensions 4.5.0\n",
            "Adding typing-extensions 4.5.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for filelock==3.13.1\n",
            "Best match: filelock 3.13.1\n",
            "Adding filelock 3.13.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for MarkupSafe==2.1.3\n",
            "Best match: MarkupSafe 2.1.3\n",
            "Adding MarkupSafe 2.1.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for certifi==2023.7.22\n",
            "Best match: certifi 2023.7.22\n",
            "Adding certifi 2023.7.22 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for urllib3==2.0.7\n",
            "Best match: urllib3 2.0.7\n",
            "Adding urllib3 2.0.7 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for idna==3.4\n",
            "Best match: idna 3.4\n",
            "Adding idna 3.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for charset-normalizer==3.3.2\n",
            "Best match: charset-normalizer 3.3.2\n",
            "Adding charset-normalizer 3.3.2 to easy-install.pth file\n",
            "Installing normalizer script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for requests-oauthlib==1.3.1\n",
            "Best match: requests-oauthlib 1.3.1\n",
            "Adding requests-oauthlib 1.3.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for rsa==4.9\n",
            "Best match: rsa 4.9\n",
            "Adding rsa 4.9 to easy-install.pth file\n",
            "Installing pyrsa-decrypt script to /usr/local/bin\n",
            "Installing pyrsa-encrypt script to /usr/local/bin\n",
            "Installing pyrsa-keygen script to /usr/local/bin\n",
            "Installing pyrsa-priv2pub script to /usr/local/bin\n",
            "Installing pyrsa-sign script to /usr/local/bin\n",
            "Installing pyrsa-verify script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for pyasn1-modules==0.3.0\n",
            "Best match: pyasn1-modules 0.3.0\n",
            "Adding pyasn1-modules 0.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for cachetools==5.3.2\n",
            "Best match: cachetools 5.3.2\n",
            "Adding cachetools 5.3.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for mpmath==1.3.0\n",
            "Best match: mpmath 1.3.0\n",
            "Adding mpmath 1.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for oauthlib==3.2.2\n",
            "Best match: oauthlib 3.2.2\n",
            "Adding oauthlib 3.2.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for pyasn1==0.5.0\n",
            "Best match: pyasn1 0.5.0\n",
            "Adding pyasn1 0.5.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Finished processing dependencies for OpenNMT-py==1.0.0\n"
          ]
        }
      ],
      "source": [
        "!python setup.py install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esaKVI-P9G2B",
        "outputId": "2e7851ee-9827-49cb-88b2-570cf0793f1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchtext==0.4.0\n",
            "  Downloading torchtext-0.4.0-py3-none-any.whl (53 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/53.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.4.0) (4.66.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.4.0) (2.31.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchtext==0.4.0) (2.1.0+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.4.0) (1.23.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from torchtext==0.4.0) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.4.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.4.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.4.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.4.0) (2023.7.22)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.4.0) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.4.0) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.4.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.4.0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.4.0) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.4.0) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.4.0) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchtext==0.4.0) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchtext==0.4.0) (1.3.0)\n",
            "Installing collected packages: torchtext\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.16.0\n",
            "    Uninstalling torchtext-0.16.0:\n",
            "      Successfully uninstalled torchtext-0.16.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opennmt-py 1.0.0 requires tqdm~=4.30.0, but you have tqdm 4.66.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torchtext-0.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torchtext==0.4.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GWa7fIp8xkn",
        "outputId": "fbaf6806-1e88-45c3-cd57-8124a8746c5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-11-18 12:10:33,761 INFO] Extracting features...\n",
            "[2023-11-18 12:10:33,765 INFO]  * number of source features: 0.\n",
            "[2023-11-18 12:10:33,765 INFO]  * number of target features: 0.\n",
            "[2023-11-18 12:10:33,765 INFO] Building `Fields` object...\n",
            "[2023-11-18 12:10:33,765 INFO] Building & saving training data...\n",
            "[2023-11-18 12:10:33,765 WARNING] Shards for corpus train already exist, will be overwritten because `-overwrite` option is set.\n",
            "[2023-11-18 12:10:33,780 WARNING] Overwrite shards for corpus None\n",
            "[2023-11-18 12:10:33,804 INFO] Building shard 0.\n",
            "[2023-11-18 12:10:34,734 INFO]  * saving 0th train data shard to data/dgs.train.0.pt.\n",
            "[2023-11-18 12:10:36,030 INFO]  * tgt vocab size: 1088.\n",
            "[2023-11-18 12:10:36,033 INFO]  * src vocab size: 2886.\n",
            "[2023-11-18 12:10:36,033 INFO]  * merging src and tgt vocab...\n",
            "[2023-11-18 12:10:36,039 INFO]  * merged vocab size: 3478.\n",
            "[2023-11-18 12:10:36,050 INFO] Building & saving validation data...\n",
            "[2023-11-18 12:10:36,051 WARNING] Shards for corpus valid already exist, will be overwritten because `-overwrite` option is set.\n",
            "[2023-11-18 12:10:36,057 WARNING] Overwrite shards for corpus None\n",
            "[2023-11-18 12:10:36,066 INFO] Building shard 0.\n",
            "[2023-11-18 12:10:36,101 INFO]  * saving 0th valid data shard to data/dgs.valid.0.pt.\n"
          ]
        }
      ],
      "source": [
        "!onmt_preprocess -train_src /content/DS605/German/Phoenix/src-train.txt -train_tgt /content/DS605/German/Phoenix/tgt-train.txt -valid_src /content/DS605/German/Phoenix/src-val.txt -valid_tgt /content/DS605/German/Phoenix/tgt-val.txt -save_data data/dgs -lower -overwrite -dynamic_dict -share_vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qA39YuA87AF",
        "outputId": "30886837-7ab9-4e2c-ec3b-d1cce57ffa7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-11-18 12:10:38,359 INFO]  * src vocab size = 3478\n",
            "[2023-11-18 12:10:38,359 INFO]  * tgt vocab size = 3478\n",
            "[2023-11-18 12:10:38,359 INFO] Building model...\n",
            "[2023-11-18 12:10:40,403 INFO] NMTModel(\n",
            "  (encoder): TransformerEncoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(3478, 512, padding_idx=1)\n",
            "        )\n",
            "        (pe): PositionalEncoding(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (transformer): ModuleList(\n",
            "      (0-1): 2 x TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (relu): ReLU()\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "  )\n",
            "  (decoder): TransformerDecoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(3478, 512, padding_idx=1)\n",
            "        )\n",
            "        (pe): PositionalEncoding(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (transformer_layers): ModuleList(\n",
            "      (0-1): 2 x TransformerDecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (context_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (relu): ReLU()\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (drop): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "  )\n",
            "  (generator): CopyGenerator(\n",
            "    (linear): Linear(in_features=512, out_features=3478, bias=True)\n",
            "    (linear_copy): Linear(in_features=512, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "[2023-11-18 12:10:40,404 INFO] encoder: 8086528\n",
            "[2023-11-18 12:10:40,404 INFO] decoder: 11974551\n",
            "[2023-11-18 12:10:40,404 INFO] * number of parameters: 20061079\n",
            "[2023-11-18 12:10:41,263 INFO] Starting training on GPU: [0]\n",
            "[2023-11-18 12:10:41,263 INFO] Start training loop and validate every 500 steps...\n",
            "[2023-11-18 12:10:41,263 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:10:42,173 INFO] number of examples: 7095\n",
            "/usr/local/lib/python3.10/dist-packages/torchtext/data/field.py:359: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  var = torch.tensor(arr, dtype=self.dtype, device=device)\n",
            "[2023-11-18 12:10:57,450 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:10:58,219 INFO] number of examples: 7095\n",
            "[2023-11-18 12:11:03,201 INFO] Step 50/100000; acc:   2.46; ppl: 1520.02; xent: 7.33; lr: 0.00000; 5942/3698 tok/s;     22 sec\n",
            "[2023-11-18 12:11:13,703 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:11:14,520 INFO] number of examples: 7095\n",
            "[2023-11-18 12:11:25,063 INFO] Step 100/100000; acc:   3.91; ppl: 941.90; xent: 6.85; lr: 0.00000; 5974/3809 tok/s;     44 sec\n",
            "[2023-11-18 12:11:25,072 INFO] Saving checkpoint model_step_100.pt\n",
            "[2023-11-18 12:11:30,630 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:11:31,617 INFO] number of examples: 7095\n",
            "[2023-11-18 12:11:45,939 INFO] Step 150/100000; acc:  11.31; ppl: 521.29; xent: 6.26; lr: 0.00001; 6234/3927 tok/s;     65 sec\n",
            "[2023-11-18 12:11:46,671 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:11:47,719 INFO] number of examples: 7095\n",
            "[2023-11-18 12:12:02,916 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:12:03,786 INFO] number of examples: 7095\n",
            "[2023-11-18 12:12:07,716 INFO] Step 200/100000; acc:  15.15; ppl: 339.63; xent: 5.83; lr: 0.00001; 5972/3704 tok/s;     86 sec\n",
            "[2023-11-18 12:12:07,736 INFO] Saving checkpoint model_step_200.pt\n",
            "[2023-11-18 12:12:19,515 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:12:20,565 INFO] number of examples: 7095\n",
            "[2023-11-18 12:12:30,169 INFO] Step 250/100000; acc:  17.45; ppl: 226.22; xent: 5.42; lr: 0.00001; 5831/3701 tok/s;    109 sec\n",
            "[2023-11-18 12:12:35,906 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:12:37,043 INFO] number of examples: 7095\n",
            "[2023-11-18 12:12:50,994 INFO] Step 300/100000; acc:  19.86; ppl: 158.40; xent: 5.07; lr: 0.00001; 6240/3945 tok/s;    130 sec\n",
            "[2023-11-18 12:12:51,005 INFO] Saving checkpoint model_step_300.pt\n",
            "[2023-11-18 12:12:53,050 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:12:53,933 INFO] number of examples: 7095\n",
            "[2023-11-18 12:13:09,216 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:13:10,295 INFO] number of examples: 7095\n",
            "[2023-11-18 12:13:13,829 INFO] Step 350/100000; acc:  20.80; ppl: 120.90; xent: 4.79; lr: 0.00002; 5692/3525 tok/s;    153 sec\n",
            "[2023-11-18 12:13:25,574 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:13:26,427 INFO] number of examples: 7095\n",
            "[2023-11-18 12:13:35,149 INFO] Step 400/100000; acc:  22.51; ppl: 90.60; xent: 4.51; lr: 0.00002; 6137/3892 tok/s;    174 sec\n",
            "[2023-11-18 12:13:35,158 INFO] Saving checkpoint model_step_400.pt\n",
            "[2023-11-18 12:13:42,175 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:13:43,240 INFO] number of examples: 7095\n",
            "[2023-11-18 12:13:56,377 INFO] Step 450/100000; acc:  23.91; ppl: 74.27; xent: 4.31; lr: 0.00002; 6116/3905 tok/s;    195 sec\n",
            "[2023-11-18 12:13:58,427 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:13:59,531 INFO] number of examples: 7095\n",
            "[2023-11-18 12:14:15,002 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:14:15,862 INFO] number of examples: 7095\n",
            "[2023-11-18 12:14:18,581 INFO] Step 500/100000; acc:  24.47; ppl: 65.47; xent: 4.18; lr: 0.00002; 5869/3613 tok/s;    217 sec\n",
            "[2023-11-18 12:14:18,582 INFO] Loading dataset from data/dgs.valid.0.pt\n",
            "[2023-11-18 12:14:18,658 INFO] number of examples: 519\n",
            "[2023-11-18 12:14:19,099 INFO] Validation perplexity: 47.651\n",
            "[2023-11-18 12:14:19,099 INFO] Validation accuracy: 29.5758\n",
            "[2023-11-18 12:14:19,099 INFO] Model is improving ppl: inf --> 47.651.\n",
            "[2023-11-18 12:14:19,099 INFO] Model is improving acc: -inf --> 29.5758.\n",
            "[2023-11-18 12:14:19,117 INFO] Saving checkpoint model_step_500.pt\n",
            "[2023-11-18 12:14:32,072 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:14:33,434 INFO] number of examples: 7095\n",
            "[2023-11-18 12:14:41,247 INFO] Step 550/100000; acc:  26.39; ppl: 55.22; xent: 4.01; lr: 0.00003; 5761/3659 tok/s;    240 sec\n",
            "[2023-11-18 12:14:48,451 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:14:49,963 INFO] number of examples: 7095\n",
            "[2023-11-18 12:15:01,969 INFO] Step 600/100000; acc:  27.67; ppl: 49.42; xent: 3.90; lr: 0.00003; 6271/3989 tok/s;    261 sec\n",
            "[2023-11-18 12:15:01,979 INFO] Saving checkpoint model_step_600.pt\n",
            "[2023-11-18 12:15:05,652 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:15:06,966 INFO] number of examples: 7095\n",
            "[2023-11-18 12:15:21,838 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:15:23,444 INFO] number of examples: 7095\n",
            "[2023-11-18 12:15:25,347 INFO] Step 650/100000; acc:  28.39; ppl: 46.48; xent: 3.84; lr: 0.00003; 5568/3444 tok/s;    284 sec\n",
            "[2023-11-18 12:15:38,331 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:15:39,664 INFO] number of examples: 7095\n",
            "[2023-11-18 12:15:46,481 INFO] Step 700/100000; acc:  30.21; ppl: 40.65; xent: 3.71; lr: 0.00003; 6183/3908 tok/s;    305 sec\n",
            "[2023-11-18 12:15:46,490 INFO] Saving checkpoint model_step_700.pt\n",
            "[2023-11-18 12:15:55,203 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:15:56,829 INFO] number of examples: 7095\n",
            "[2023-11-18 12:16:07,970 INFO] Step 750/100000; acc:  31.84; ppl: 36.37; xent: 3.59; lr: 0.00004; 6057/3860 tok/s;    327 sec\n",
            "[2023-11-18 12:16:12,027 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:16:13,327 INFO] number of examples: 7095\n",
            "[2023-11-18 12:16:28,165 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:16:29,717 INFO] number of examples: 7095\n",
            "[2023-11-18 12:16:30,755 INFO] Step 800/100000; acc:  32.65; ppl: 34.07; xent: 3.53; lr: 0.00004; 5726/3556 tok/s;    349 sec\n",
            "[2023-11-18 12:16:30,773 INFO] Saving checkpoint model_step_800.pt\n",
            "[2023-11-18 12:16:45,318 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:16:46,943 INFO] number of examples: 7095\n",
            "[2023-11-18 12:16:52,442 INFO] Step 850/100000; acc:  34.22; ppl: 30.54; xent: 3.42; lr: 0.00004; 6005/3773 tok/s;    371 sec\n",
            "[2023-11-18 12:17:01,766 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:17:03,179 INFO] number of examples: 7095\n",
            "[2023-11-18 12:17:12,999 INFO] Step 900/100000; acc:  35.70; ppl: 27.17; xent: 3.30; lr: 0.00004; 6333/4043 tok/s;    392 sec\n",
            "[2023-11-18 12:17:13,016 INFO] Saving checkpoint model_step_900.pt\n",
            "[2023-11-18 12:17:19,431 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:17:20,994 INFO] number of examples: 7095\n",
            "[2023-11-18 12:17:36,077 INFO] Step 950/100000; acc:  36.59; ppl: 25.25; xent: 3.23; lr: 0.00005; 5648/3525 tok/s;    415 sec\n",
            "[2023-11-18 12:17:36,078 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:17:37,595 INFO] number of examples: 7095\n",
            "[2023-11-18 12:17:52,375 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:17:53,595 INFO] number of examples: 7095\n",
            "[2023-11-18 12:17:57,965 INFO] Step 1000/100000; acc:  37.59; ppl: 23.06; xent: 3.14; lr: 0.00005; 5955/3706 tok/s;    437 sec\n",
            "[2023-11-18 12:17:57,966 INFO] Loading dataset from data/dgs.valid.0.pt\n",
            "[2023-11-18 12:17:58,011 INFO] number of examples: 519\n",
            "[2023-11-18 12:17:58,341 INFO] Validation perplexity: 19.3897\n",
            "[2023-11-18 12:17:58,341 INFO] Validation accuracy: 40.45\n",
            "[2023-11-18 12:17:58,341 INFO] Model is improving ppl: 47.651 --> 19.3897.\n",
            "[2023-11-18 12:17:58,341 INFO] Model is improving acc: 29.5758 --> 40.45.\n",
            "[2023-11-18 12:17:58,351 INFO] Saving checkpoint model_step_1000.pt\n",
            "[2023-11-18 12:18:09,922 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:18:10,946 INFO] number of examples: 7095\n",
            "[2023-11-18 12:18:19,361 INFO] Step 1050/100000; acc:  39.49; ppl: 20.42; xent: 3.02; lr: 0.00005; 6104/3892 tok/s;    458 sec\n",
            "[2023-11-18 12:18:26,056 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:18:27,136 INFO] number of examples: 7095\n",
            "[2023-11-18 12:18:41,525 INFO] Step 1100/100000; acc:  40.27; ppl: 18.96; xent: 2.94; lr: 0.00005; 5872/3699 tok/s;    480 sec\n",
            "[2023-11-18 12:18:41,542 INFO] Saving checkpoint model_step_1100.pt\n",
            "[2023-11-18 12:18:42,991 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:18:43,867 INFO] number of examples: 7095\n",
            "[2023-11-18 12:18:59,039 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:19:00,092 INFO] number of examples: 7095\n",
            "[2023-11-18 12:19:03,761 INFO] Step 1150/100000; acc:  41.11; ppl: 17.73; xent: 2.87; lr: 0.00006; 5849/3628 tok/s;    502 sec\n",
            "[2023-11-18 12:19:15,527 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:19:16,633 INFO] number of examples: 7095\n",
            "[2023-11-18 12:19:24,593 INFO] Step 1200/100000; acc:  42.32; ppl: 16.10; xent: 2.78; lr: 0.00006; 6285/3989 tok/s;    523 sec\n",
            "[2023-11-18 12:19:24,611 INFO] Saving checkpoint model_step_1200.pt\n",
            "[2023-11-18 12:19:32,592 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:19:33,466 INFO] number of examples: 7095\n",
            "[2023-11-18 12:19:47,283 INFO] Step 1250/100000; acc:  44.13; ppl: 14.50; xent: 2.67; lr: 0.00006; 5727/3621 tok/s;    546 sec\n",
            "[2023-11-18 12:19:48,766 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:19:49,841 INFO] number of examples: 7095\n",
            "[2023-11-18 12:20:05,353 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:20:06,468 INFO] number of examples: 7095\n",
            "[2023-11-18 12:20:09,302 INFO] Step 1300/100000; acc:  44.73; ppl: 13.79; xent: 2.62; lr: 0.00006; 5903/3655 tok/s;    568 sec\n",
            "[2023-11-18 12:20:09,311 INFO] Saving checkpoint model_step_1300.pt\n",
            "[2023-11-18 12:20:22,464 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:20:23,334 INFO] number of examples: 7095\n",
            "[2023-11-18 12:20:30,826 INFO] Step 1350/100000; acc:  46.73; ppl: 12.16; xent: 2.50; lr: 0.00007; 6079/3855 tok/s;    590 sec\n",
            "[2023-11-18 12:20:38,684 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:20:39,792 INFO] number of examples: 7095\n",
            "[2023-11-18 12:20:52,972 INFO] Step 1400/100000; acc:  47.93; ppl: 11.27; xent: 2.42; lr: 0.00007; 5862/3743 tok/s;    612 sec\n",
            "[2023-11-18 12:20:52,982 INFO] Saving checkpoint model_step_1400.pt\n",
            "[2023-11-18 12:20:55,594 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:20:56,478 INFO] number of examples: 7095\n",
            "[2023-11-18 12:21:11,580 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:21:12,681 INFO] number of examples: 7095\n",
            "[2023-11-18 12:21:14,779 INFO] Step 1450/100000; acc:  48.61; ppl: 10.78; xent: 2.38; lr: 0.00007; 5975/3679 tok/s;    634 sec\n",
            "[2023-11-18 12:21:27,954 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:21:28,820 INFO] number of examples: 7095\n",
            "[2023-11-18 12:21:35,591 INFO] Step 1500/100000; acc:  50.48; ppl:  9.60; xent: 2.26; lr: 0.00007; 6275/3985 tok/s;    654 sec\n",
            "[2023-11-18 12:21:35,592 INFO] Loading dataset from data/dgs.valid.0.pt\n",
            "[2023-11-18 12:21:35,667 INFO] number of examples: 519\n",
            "[2023-11-18 12:21:36,116 INFO] Validation perplexity: 11.9717\n",
            "[2023-11-18 12:21:36,116 INFO] Validation accuracy: 48.2306\n",
            "[2023-11-18 12:21:36,116 INFO] Model is improving ppl: 19.3897 --> 11.9717.\n",
            "[2023-11-18 12:21:36,116 INFO] Model is improving acc: 40.45 --> 48.2306.\n",
            "[2023-11-18 12:21:36,134 INFO] Saving checkpoint model_step_1500.pt\n",
            "[2023-11-18 12:21:44,903 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:21:45,955 INFO] number of examples: 7095\n",
            "[2023-11-18 12:21:58,387 INFO] Step 1550/100000; acc:  51.53; ppl:  9.02; xent: 2.20; lr: 0.00008; 5701/3626 tok/s;    677 sec\n",
            "[2023-11-18 12:22:01,129 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:22:02,321 INFO] number of examples: 7095\n",
            "[2023-11-18 12:22:17,720 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:22:18,588 INFO] number of examples: 7095\n",
            "[2023-11-18 12:22:20,060 INFO] Step 1600/100000; acc:  52.27; ppl:  8.61; xent: 2.15; lr: 0.00008; 6007/3715 tok/s;    699 sec\n",
            "[2023-11-18 12:22:20,070 INFO] Saving checkpoint model_step_1600.pt\n",
            "[2023-11-18 12:22:34,852 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:22:35,967 INFO] number of examples: 7095\n",
            "[2023-11-18 12:22:42,697 INFO] Step 1650/100000; acc:  53.40; ppl:  7.90; xent: 2.07; lr: 0.00008; 5773/3649 tok/s;    721 sec\n",
            "[2023-11-18 12:22:51,348 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:22:52,237 INFO] number of examples: 7095\n",
            "[2023-11-18 12:23:04,199 INFO] Step 1700/100000; acc:  54.61; ppl:  7.41; xent: 2.00; lr: 0.00008; 6053/3858 tok/s;    743 sec\n",
            "[2023-11-18 12:23:04,217 INFO] Saving checkpoint model_step_1700.pt\n",
            "[2023-11-18 12:23:08,489 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:23:09,563 INFO] number of examples: 7095\n",
            "[2023-11-18 12:23:25,270 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:23:26,348 INFO] number of examples: 7095\n",
            "[2023-11-18 12:23:27,115 INFO] Step 1750/100000; acc:  54.97; ppl:  7.07; xent: 1.96; lr: 0.00009; 5693/3535 tok/s;    766 sec\n",
            "[2023-11-18 12:23:41,680 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:23:42,782 INFO] number of examples: 7095\n",
            "[2023-11-18 12:23:48,854 INFO] Step 1800/100000; acc:  56.48; ppl:  6.60; xent: 1.89; lr: 0.00009; 5991/3764 tok/s;    788 sec\n",
            "[2023-11-18 12:23:48,874 INFO] Saving checkpoint model_step_1800.pt\n",
            "[2023-11-18 12:23:58,703 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:23:59,597 INFO] number of examples: 7095\n",
            "[2023-11-18 12:24:10,748 INFO] Step 1850/100000; acc:  57.49; ppl:  6.16; xent: 1.82; lr: 0.00009; 5947/3796 tok/s;    809 sec\n",
            "[2023-11-18 12:24:14,984 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:24:16,087 INFO] number of examples: 7095\n",
            "[2023-11-18 12:24:31,019 INFO] Step 1900/100000; acc:  58.47; ppl:  5.85; xent: 1.77; lr: 0.00009; 6430/4013 tok/s;    830 sec\n",
            "[2023-11-18 12:24:31,030 INFO] Saving checkpoint model_step_1900.pt\n",
            "[2023-11-18 12:24:31,549 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:24:32,477 INFO] number of examples: 7095\n",
            "[2023-11-18 12:24:47,578 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:24:48,678 INFO] number of examples: 7095\n",
            "[2023-11-18 12:24:54,092 INFO] Step 1950/100000; acc:  58.85; ppl:  5.61; xent: 1.72; lr: 0.00010; 5649/3516 tok/s;    853 sec\n",
            "[2023-11-18 12:25:03,706 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:25:04,626 INFO] number of examples: 7095\n",
            "[2023-11-18 12:25:14,638 INFO] Step 2000/100000; acc:  60.18; ppl:  5.28; xent: 1.66; lr: 0.00010; 6356/4053 tok/s;    873 sec\n",
            "[2023-11-18 12:25:14,638 INFO] Loading dataset from data/dgs.valid.0.pt\n",
            "[2023-11-18 12:25:14,683 INFO] number of examples: 519\n",
            "[2023-11-18 12:25:14,992 INFO] Validation perplexity: 12.1122\n",
            "[2023-11-18 12:25:14,993 INFO] Validation accuracy: 49.1446\n",
            "[2023-11-18 12:25:14,993 INFO] Stalled patience: 2/3\n",
            "[2023-11-18 12:25:15,002 INFO] Saving checkpoint model_step_2000.pt\n",
            "[2023-11-18 12:25:20,513 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:25:21,592 INFO] number of examples: 7095\n",
            "[2023-11-18 12:25:36,089 INFO] Step 2050/100000; acc:  60.90; ppl:  5.03; xent: 1.61; lr: 0.00010; 6067/3821 tok/s;    895 sec\n",
            "[2023-11-18 12:25:36,839 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:25:38,077 INFO] number of examples: 7095\n",
            "[2023-11-18 12:25:53,102 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:25:54,120 INFO] number of examples: 7095\n",
            "[2023-11-18 12:25:59,036 INFO] Step 2100/100000; acc:  62.31; ppl:  4.72; xent: 1.55; lr: 0.00010; 5668/3515 tok/s;    918 sec\n",
            "[2023-11-18 12:25:59,062 INFO] Saving checkpoint model_step_2100.pt\n",
            "[2023-11-18 12:26:10,135 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:26:11,737 INFO] number of examples: 7095\n",
            "[2023-11-18 12:26:20,769 INFO] Step 2150/100000; acc:  63.55; ppl:  4.42; xent: 1.49; lr: 0.00010; 6025/3824 tok/s;    940 sec\n",
            "[2023-11-18 12:26:26,861 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:26:28,190 INFO] number of examples: 7095\n",
            "[2023-11-18 12:26:41,862 INFO] Step 2200/100000; acc:  64.73; ppl:  4.16; xent: 1.43; lr: 0.00009; 6161/3895 tok/s;    961 sec\n",
            "[2023-11-18 12:26:41,879 INFO] Saving checkpoint model_step_2200.pt\n",
            "[2023-11-18 12:26:44,313 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:26:45,966 INFO] number of examples: 7095\n",
            "[2023-11-18 12:27:01,760 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:27:03,247 INFO] number of examples: 7095\n",
            "[2023-11-18 12:27:06,882 INFO] Step 2250/100000; acc:  65.47; ppl:  3.97; xent: 1.38; lr: 0.00009; 5195/3217 tok/s;    986 sec\n",
            "[2023-11-18 12:27:18,767 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:27:20,526 INFO] number of examples: 7095\n",
            "[2023-11-18 12:27:28,049 INFO] Step 2300/100000; acc:  66.41; ppl:  3.80; xent: 1.33; lr: 0.00009; 6182/3920 tok/s;   1007 sec\n",
            "[2023-11-18 12:27:28,059 INFO] Saving checkpoint model_step_2300.pt\n",
            "[2023-11-18 12:27:36,514 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:27:37,891 INFO] number of examples: 7095\n",
            "[2023-11-18 12:27:50,213 INFO] Step 2350/100000; acc:  67.02; ppl:  3.68; xent: 1.30; lr: 0.00009; 5857/3740 tok/s;   1029 sec\n",
            "[2023-11-18 12:27:53,036 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:27:54,552 INFO] number of examples: 7095\n",
            "[2023-11-18 12:28:10,300 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:28:11,254 INFO] number of examples: 7095\n",
            "[2023-11-18 12:28:13,402 INFO] Step 2400/100000; acc:  67.92; ppl:  3.51; xent: 1.26; lr: 0.00009; 5619/3460 tok/s;   1052 sec\n",
            "[2023-11-18 12:28:13,412 INFO] Saving checkpoint model_step_2400.pt\n",
            "[2023-11-18 12:28:27,152 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:28:28,231 INFO] number of examples: 7095\n",
            "[2023-11-18 12:28:34,566 INFO] Step 2450/100000; acc:  69.04; ppl:  3.33; xent: 1.20; lr: 0.00009; 6170/3919 tok/s;   1073 sec\n",
            "[2023-11-18 12:28:43,445 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:28:44,297 INFO] number of examples: 7095\n",
            "[2023-11-18 12:28:55,716 INFO] Step 2500/100000; acc:  70.08; ppl:  3.20; xent: 1.16; lr: 0.00009; 6144/3908 tok/s;   1094 sec\n",
            "[2023-11-18 12:28:55,717 INFO] Loading dataset from data/dgs.valid.0.pt\n",
            "[2023-11-18 12:28:55,791 INFO] number of examples: 519\n",
            "[2023-11-18 12:28:56,245 INFO] Validation perplexity: 14.7556\n",
            "[2023-11-18 12:28:56,245 INFO] Validation accuracy: 48.4415\n",
            "[2023-11-18 12:28:56,245 INFO] Stalled patience: 1/3\n",
            "[2023-11-18 12:28:56,265 INFO] Saving checkpoint model_step_2500.pt\n",
            "[2023-11-18 12:29:00,446 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:29:01,506 INFO] number of examples: 7095\n",
            "[2023-11-18 12:29:16,885 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:29:17,921 INFO] number of examples: 7095\n",
            "[2023-11-18 12:29:19,331 INFO] Step 2550/100000; acc:  70.38; ppl:  3.14; xent: 1.14; lr: 0.00009; 5513/3409 tok/s;   1118 sec\n",
            "[2023-11-18 12:29:33,452 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:29:34,523 INFO] number of examples: 7095\n",
            "[2023-11-18 12:29:40,332 INFO] Step 2600/100000; acc:  70.33; ppl:  3.09; xent: 1.13; lr: 0.00009; 6222/3933 tok/s;   1139 sec\n",
            "[2023-11-18 12:29:40,341 INFO] Saving checkpoint model_step_2600.pt\n",
            "[2023-11-18 12:29:50,455 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:29:51,584 INFO] number of examples: 7095\n",
            "[2023-11-18 12:30:02,891 INFO] Step 2650/100000; acc:  71.14; ppl:  2.99; xent: 1.09; lr: 0.00009; 5769/3677 tok/s;   1162 sec\n",
            "[2023-11-18 12:30:07,086 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:30:07,988 INFO] number of examples: 7095\n",
            "[2023-11-18 12:30:23,438 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:30:24,593 INFO] number of examples: 7095\n",
            "[2023-11-18 12:30:25,383 INFO] Step 2700/100000; acc:  73.45; ppl:  2.76; xent: 1.02; lr: 0.00009; 5801/3602 tok/s;   1184 sec\n",
            "[2023-11-18 12:30:25,394 INFO] Saving checkpoint model_step_2700.pt\n",
            "[2023-11-18 12:30:40,722 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:30:41,625 INFO] number of examples: 7095\n",
            "[2023-11-18 12:30:46,697 INFO] Step 2750/100000; acc:  74.55; ppl:  2.61; xent: 0.96; lr: 0.00008; 6110/3839 tok/s;   1205 sec\n",
            "[2023-11-18 12:30:57,091 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:30:58,257 INFO] number of examples: 7095\n",
            "[2023-11-18 12:31:09,742 INFO] Step 2800/100000; acc:  75.36; ppl:  2.53; xent: 0.93; lr: 0.00008; 5649/3606 tok/s;   1228 sec\n",
            "[2023-11-18 12:31:09,752 INFO] Saving checkpoint model_step_2800.pt\n",
            "[2023-11-18 12:31:14,629 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:31:15,531 INFO] number of examples: 7095\n",
            "[2023-11-18 12:31:31,063 INFO] Step 2850/100000; acc:  76.90; ppl:  2.39; xent: 0.87; lr: 0.00008; 6114/3815 tok/s;   1250 sec\n",
            "[2023-11-18 12:31:31,063 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:31:32,241 INFO] number of examples: 7095\n",
            "[2023-11-18 12:31:47,915 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:31:48,804 INFO] number of examples: 7095\n",
            "[2023-11-18 12:31:53,649 INFO] Step 2900/100000; acc:  77.61; ppl:  2.32; xent: 0.84; lr: 0.00008; 5771/3592 tok/s;   1272 sec\n",
            "[2023-11-18 12:31:53,670 INFO] Saving checkpoint model_step_2900.pt\n",
            "[2023-11-18 12:32:05,206 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:32:06,375 INFO] number of examples: 7095\n",
            "[2023-11-18 12:32:16,849 INFO] Step 2950/100000; acc:  78.16; ppl:  2.27; xent: 0.82; lr: 0.00008; 5629/3589 tok/s;   1296 sec\n",
            "[2023-11-18 12:32:22,127 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2023-11-18 12:32:23,021 INFO] number of examples: 7095\n",
            "[2023-11-18 12:32:39,220 INFO] Step 3000/100000; acc:  79.17; ppl:  2.18; xent: 0.78; lr: 0.00008; 5817/3664 tok/s;   1318 sec\n",
            "[2023-11-18 12:32:39,221 INFO] Loading dataset from data/dgs.valid.0.pt\n",
            "[2023-11-18 12:32:39,277 INFO] number of examples: 519\n",
            "[2023-11-18 12:32:39,588 INFO] Validation perplexity: 18.5027\n",
            "[2023-11-18 12:32:39,588 INFO] Validation accuracy: 48.629\n",
            "[2023-11-18 12:32:39,588 INFO] Stalled patience: 0/3\n",
            "[2023-11-18 12:32:39,588 INFO] Training finished after stalled validations. Early Stop!\n",
            "[2023-11-18 12:32:39,588 INFO] Best model found at step 1500\n",
            "[2023-11-18 12:32:39,599 INFO] Saving checkpoint model_step_3000.pt\n"
          ]
        }
      ],
      "source": [
        "!python  train.py -data data/dgs -save_model model -keep_checkpoint 1 \\\n",
        "          -layers 2 -rnn_size 512 -word_vec_size 512 -transformer_ff 2048 -heads 8  \\\n",
        "          -encoder_type transformer -decoder_type transformer -position_encoding \\\n",
        "          -max_generator_batches 2 -dropout 0.1 \\\n",
        "          -early_stopping 3 -early_stopping_criteria accuracy ppl \\\n",
        "          -batch_size 1024 -accum_count 3 -batch_type tokens -normalization tokens \\\n",
        "          -optim adam -adam_beta2 0.998 -decay_method noam -warmup_steps 2000 -learning_rate 0.1 \\\n",
        "          -max_grad_norm 0 -param_init 0  -param_init_glorot \\\n",
        "          -label_smoothing 0.1 -valid_steps 500 -save_checkpoint_steps 100 \\\n",
        "          -world_size 1 -gpu_ranks 0 -copy_attn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 translate.py -model model_step_3000.pt -src /content/DS605/German/Phoenix/src-test.txt -output gloss.txt -gpu 0 -replace_unk -beam_size 4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIg7161JYdXk",
        "outputId": "d6a852ed-549e-4d8a-af3d-24d2311416cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-11-18 12:37:58,554 INFO] Translating shard 0.\n",
            "/usr/local/lib/python3.10/dist-packages/torchtext/data/field.py:359: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  var = torch.tensor(arr, dtype=self.dtype, device=device)\n",
            "/content/transformer-slt/onmt/translate/beam_search.py:187: UserWarning: An output with one or more elements was resized since it had shape [120], which does not match the required output shape [30, 4]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
            "  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)\n",
            "/content/transformer-slt/onmt/translate/beam_search.py:187: UserWarning: An output with one or more elements was resized since it had shape [48], which does not match the required output shape [12, 4]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
            "  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)\n",
            "PRED AVG SCORE: -0.4989, PRED PPL: 1.6470\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python tools/bleu.py 1 gloss.txt /content/DS605/German/Phoenix/tgt-test.txt\n",
        "!python tools/bleu.py 2 gloss.txt /content/DS605/German/Phoenix/tgt-test.txt\n",
        "!python tools/bleu.py 3 gloss.txt /content/DS605/German/Phoenix/tgt-test.txt\n",
        "!python tools/bleu.py 4 gloss.txt /content/DS605/German/Phoenix/tgt-test.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNIrAR4za5UL",
        "outputId": "39f99525-9ba9-4a6b-8d00-50bf85b622c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.56194895033537\n",
            "0.3777935142490518\n",
            "0.2677180256326812\n",
            "0.19322513046102333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8oDg2exO_61",
        "outputId": "2844bbd7-1296-4e63-8a12-b532d6c6b723"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rain Alps ix snow otherwise region northeast a little bit showers\n",
            "Thursday north rain south then sun cloud then on Friday too\n",
            "north sea deep come so rain can freeze smooth rain\n",
            "Weekends in-past sun day Saturday one to seventeen degrees West region seventeen degrees\n",
            "tomorrow region high pressure cloud sky\n",
            "Sunday northwest changeable sun cloud sun thunderstorms\n",
            "Place of thunderstorms\n",
            "Incoming continued snow again and again\n",
            "Saturday Sunday a bit cold\n",
            "Tomorrow weather calm high fog cloud sun\n",
            "Spaeter fog high fog\n",
            "disappear tomorrow fog\n",
            "Germany only for twenty\n",
            "Mitte sea moist, thunderstorms\n",
            "Temperature like today six to eleven degrees\n",
            "North Night start at the beginning of show thunderstorms then clearly clear\n",
            "Until evening IX snow border\n",
            "Now weather tomorrow Friday Fuenfteen October\n",
            "Tomorrow frueh north deep come so rain\n",
            "tonight sued part clear heaven but fog\n"
          ]
        }
      ],
      "source": [
        "from googletrans import Translator\n",
        "# Create a Translator object\n",
        "translator = Translator()\n",
        "with open(\"gloss.txt\", 'r', encoding='utf-8') as file:\n",
        "        lines = file.readlines()\n",
        "for line in lines[:20]:\n",
        "        translated_text = translator.translate(line, src='de', dest='en').text\n",
        "        print(translated_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRZ071FpelLA",
        "outputId": "92eef670-c4af-4b15-8b9b-34397d361292"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r \"/content/drive/MyDrive/DS605 SLT\" \"/content\""
      ],
      "metadata": {
        "id": "jUiEYq-helHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ENGLISH DATA"
      ],
      "metadata": {
        "id": "g0-r57udcGiI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!onmt_preprocess -train_src /content/DS605/English/ASLG_Processed/src-train.txt -train_tgt /content/DS605/English/ASLG_Processed/tgt-train.txt -valid_src /content/DS605/English/ASLG_Processed/src-val.txt -valid_tgt /content/DS605/English/ASLG_Processed/tgt-val.txt -save_data data/asl -lower -overwrite -dynamic_dict -share_vocab"
      ],
      "metadata": {
        "id": "WreZc9qIelEp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49287101-fd8f-4742-ed5d-d448dfe30269"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-11-18 12:42:16,649 INFO] Extracting features...\n",
            "[2023-11-18 12:42:17,994 INFO]  * number of source features: 0.\n",
            "[2023-11-18 12:42:17,994 INFO]  * number of target features: 0.\n",
            "[2023-11-18 12:42:17,994 INFO] Building `Fields` object...\n",
            "[2023-11-18 12:42:17,995 INFO] Building & saving training data...\n",
            "[2023-11-18 12:42:18,982 INFO] Building shard 0.\n",
            "[2023-11-18 12:42:29,459 INFO]  * saving 0th train data shard to data/asl.train.0.pt.\n",
            "[2023-11-18 12:42:47,175 INFO]  * tgt vocab size: 15729.\n",
            "[2023-11-18 12:42:47,200 INFO]  * src vocab size: 21599.\n",
            "[2023-11-18 12:42:47,200 INFO]  * merging src and tgt vocab...\n",
            "[2023-11-18 12:42:47,243 INFO]  * merged vocab size: 24090.\n",
            "[2023-11-18 12:42:47,294 INFO] Building & saving validation data...\n",
            "[2023-11-18 12:42:48,259 INFO] Building shard 0.\n",
            "[2023-11-18 12:42:48,613 INFO]  * saving 0th valid data shard to data/asl.valid.0.pt.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python  train.py -data data/asl -save_model model_asl -keep_checkpoint 1 \\\n",
        "          -layers 2 -rnn_size 512 -word_vec_size 512 -transformer_ff 2048 -heads 8  \\\n",
        "          -encoder_type transformer -decoder_type transformer -position_encoding \\\n",
        "          -max_generator_batches 2 -dropout 0.1 \\\n",
        "          -early_stopping 3 -early_stopping_criteria accuracy ppl \\\n",
        "          -batch_size 1024 -accum_count 3 -batch_type tokens -normalization tokens \\\n",
        "          -optim adam -adam_beta2 0.998 -decay_method noam -warmup_steps 2000 -learning_rate 0.1 \\\n",
        "          -max_grad_norm 0 -param_init 0  -param_init_glorot \\\n",
        "          -label_smoothing 0.1 -valid_steps 500 -save_checkpoint_steps 100 \\\n",
        "          -world_size 1 -gpu_ranks 0 -copy_attn"
      ],
      "metadata": {
        "id": "D9Lw7GZ-elBP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ec9e061-56b3-49ed-dcfa-e910c6616789"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-11-18 12:43:28,827 INFO]  * src vocab size = 24090\n",
            "[2023-11-18 12:43:28,827 INFO]  * tgt vocab size = 24090\n",
            "[2023-11-18 12:43:28,827 INFO] Building model...\n",
            "[2023-11-18 12:43:31,330 INFO] NMTModel(\n",
            "  (encoder): TransformerEncoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(24090, 512, padding_idx=1)\n",
            "        )\n",
            "        (pe): PositionalEncoding(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (transformer): ModuleList(\n",
            "      (0-1): 2 x TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (relu): ReLU()\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "  )\n",
            "  (decoder): TransformerDecoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(24090, 512, padding_idx=1)\n",
            "        )\n",
            "        (pe): PositionalEncoding(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (transformer_layers): ModuleList(\n",
            "      (0-1): 2 x TransformerDecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (context_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (relu): ReLU()\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (drop): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "  )\n",
            "  (generator): CopyGenerator(\n",
            "    (linear): Linear(in_features=512, out_features=24090, bias=True)\n",
            "    (linear_copy): Linear(in_features=512, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "[2023-11-18 12:43:31,331 INFO] encoder: 18639872\n",
            "[2023-11-18 12:43:31,331 INFO] decoder: 33101851\n",
            "[2023-11-18 12:43:31,331 INFO] * number of parameters: 51741723\n",
            "[2023-11-18 12:43:32,144 INFO] Starting training on GPU: [0]\n",
            "[2023-11-18 12:43:32,144 INFO] Start training loop and validate every 500 steps...\n",
            "[2023-11-18 12:43:32,144 INFO] Loading dataset from data/asl.train.0.pt\n",
            "[2023-11-18 12:43:44,691 INFO] number of examples: 82706\n",
            "/usr/local/lib/python3.10/dist-packages/torchtext/data/field.py:359: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  var = torch.tensor(arr, dtype=self.dtype, device=device)\n",
            "[2023-11-18 12:44:10,705 INFO] Step 50/100000; acc:   7.05; ppl: 216.71; xent: 5.38; lr: 0.00000; 3412/3307 tok/s;     39 sec\n",
            "[2023-11-18 12:44:36,357 INFO] Step 100/100000; acc:  10.55; ppl: 168.82; xent: 5.13; lr: 0.00000; 5126/5024 tok/s;     64 sec\n",
            "[2023-11-18 12:44:36,417 INFO] Saving checkpoint model_asl_step_100.pt\n",
            "[2023-11-18 12:45:05,762 INFO] Step 150/100000; acc:  18.42; ppl: 105.97; xent: 4.66; lr: 0.00001; 4491/4423 tok/s;     94 sec\n",
            "[2023-11-18 12:45:30,478 INFO] Step 200/100000; acc:  25.69; ppl: 66.00; xent: 4.19; lr: 0.00001; 5374/5166 tok/s;    118 sec\n",
            "[2023-11-18 12:45:30,537 INFO] Saving checkpoint model_asl_step_200.pt\n",
            "[2023-11-18 12:45:58,364 INFO] Step 250/100000; acc:  30.50; ppl: 48.22; xent: 3.88; lr: 0.00001; 4760/4605 tok/s;    146 sec\n",
            "[2023-11-18 12:46:23,926 INFO] Step 300/100000; acc:  35.10; ppl: 35.90; xent: 3.58; lr: 0.00001; 5149/5032 tok/s;    172 sec\n",
            "[2023-11-18 12:46:24,034 INFO] Saving checkpoint model_asl_step_300.pt\n",
            "[2023-11-18 12:46:50,643 INFO] Step 350/100000; acc:  37.50; ppl: 28.64; xent: 3.35; lr: 0.00002; 4921/4766 tok/s;    198 sec\n",
            "[2023-11-18 12:47:16,423 INFO] Step 400/100000; acc:  41.60; ppl: 22.35; xent: 3.11; lr: 0.00002; 5154/4966 tok/s;    224 sec\n",
            "[2023-11-18 12:47:16,480 INFO] Saving checkpoint model_asl_step_400.pt\n",
            "[2023-11-18 12:47:23,735 INFO] Loading dataset from data/asl.train.0.pt\n",
            "[2023-11-18 12:47:36,899 INFO] number of examples: 82706\n",
            "[2023-11-18 12:47:57,127 INFO] Step 450/100000; acc:  47.90; ppl: 17.82; xent: 2.88; lr: 0.00002; 3230/3132 tok/s;    265 sec\n",
            "[2023-11-18 12:48:22,820 INFO] Step 500/100000; acc:  55.74; ppl: 13.15; xent: 2.58; lr: 0.00002; 5133/4983 tok/s;    291 sec\n",
            "[2023-11-18 12:48:22,821 INFO] Loading dataset from data/asl.valid.0.pt\n",
            "[2023-11-18 12:48:23,166 INFO] number of examples: 4000\n",
            "[2023-11-18 12:48:26,105 INFO] Validation perplexity: 9.5702\n",
            "[2023-11-18 12:48:26,105 INFO] Validation accuracy: 66.9175\n",
            "[2023-11-18 12:48:26,105 INFO] Model is improving ppl: inf --> 9.5702.\n",
            "[2023-11-18 12:48:26,105 INFO] Model is improving acc: -inf --> 66.9175.\n",
            "[2023-11-18 12:48:26,164 INFO] Saving checkpoint model_asl_step_500.pt\n",
            "[2023-11-18 12:48:54,601 INFO] Step 550/100000; acc:  62.51; ppl:  9.98; xent: 2.30; lr: 0.00003; 4142/4101 tok/s;    322 sec\n",
            "[2023-11-18 12:49:19,863 INFO] Step 600/100000; acc:  62.54; ppl:  9.55; xent: 2.26; lr: 0.00003; 5259/5092 tok/s;    348 sec\n",
            "[2023-11-18 12:49:19,973 INFO] Saving checkpoint model_asl_step_600.pt\n",
            "[2023-11-18 12:49:47,207 INFO] Step 650/100000; acc:  66.88; ppl:  7.71; xent: 2.04; lr: 0.00003; 4854/4665 tok/s;    375 sec\n",
            "[2023-11-18 12:50:13,451 INFO] Step 700/100000; acc:  68.94; ppl:  6.78; xent: 1.91; lr: 0.00003; 5021/4894 tok/s;    401 sec\n",
            "[2023-11-18 12:50:13,511 INFO] Saving checkpoint model_asl_step_700.pt\n",
            "[2023-11-18 12:50:40,682 INFO] Step 750/100000; acc:  71.84; ppl:  5.78; xent: 1.76; lr: 0.00004; 4842/4690 tok/s;    429 sec\n",
            "[2023-11-18 12:51:05,806 INFO] Step 800/100000; acc:  72.70; ppl:  5.54; xent: 1.71; lr: 0.00004; 5267/5099 tok/s;    454 sec\n",
            "[2023-11-18 12:51:05,865 INFO] Saving checkpoint model_asl_step_800.pt\n",
            "[2023-11-18 12:51:19,639 INFO] Loading dataset from data/asl.train.0.pt\n",
            "[2023-11-18 12:51:34,002 INFO] number of examples: 82706\n",
            "[2023-11-18 12:51:49,706 INFO] Step 850/100000; acc:  74.98; ppl:  5.10; xent: 1.63; lr: 0.00004; 3002/2906 tok/s;    498 sec\n",
            "[2023-11-18 12:52:14,506 INFO] Step 900/100000; acc:  74.97; ppl:  4.92; xent: 1.59; lr: 0.00004; 5312/5167 tok/s;    522 sec\n",
            "[2023-11-18 12:52:14,568 INFO] Saving checkpoint model_asl_step_900.pt\n",
            "[2023-11-18 12:52:42,792 INFO] Step 950/100000; acc:  77.95; ppl:  4.26; xent: 1.45; lr: 0.00005; 4656/4584 tok/s;    551 sec\n",
            "[2023-11-18 12:53:09,068 INFO] Step 1000/100000; acc:  76.45; ppl:  4.68; xent: 1.54; lr: 0.00005; 5061/4893 tok/s;    577 sec\n",
            "[2023-11-18 12:53:09,069 INFO] Loading dataset from data/asl.valid.0.pt\n",
            "[2023-11-18 12:53:09,522 INFO] number of examples: 4000\n",
            "[2023-11-18 12:53:12,524 INFO] Validation perplexity: 4.27118\n",
            "[2023-11-18 12:53:12,525 INFO] Validation accuracy: 76.4157\n",
            "[2023-11-18 12:53:12,525 INFO] Model is improving ppl: 9.5702 --> 4.27118.\n",
            "[2023-11-18 12:53:12,525 INFO] Model is improving acc: 66.9175 --> 76.4157.\n",
            "[2023-11-18 12:53:12,585 INFO] Saving checkpoint model_asl_step_1000.pt\n",
            "[2023-11-18 12:53:42,827 INFO] Step 1050/100000; acc:  78.07; ppl:  4.16; xent: 1.43; lr: 0.00005; 3914/3790 tok/s;    611 sec\n",
            "[2023-11-18 12:54:08,052 INFO] Step 1100/100000; acc:  76.65; ppl:  4.42; xent: 1.49; lr: 0.00005; 5250/5103 tok/s;    636 sec\n",
            "[2023-11-18 12:54:08,173 INFO] Saving checkpoint model_asl_step_1100.pt\n",
            "[2023-11-18 12:54:36,048 INFO] Step 1150/100000; acc:  77.49; ppl:  4.05; xent: 1.40; lr: 0.00006; 4702/4579 tok/s;    664 sec\n",
            "[2023-11-18 12:55:02,742 INFO] Step 1200/100000; acc:  77.30; ppl:  4.17; xent: 1.43; lr: 0.00006; 4946/4796 tok/s;    691 sec\n",
            "[2023-11-18 12:55:02,857 INFO] Saving checkpoint model_asl_step_1200.pt\n",
            "[2023-11-18 12:55:21,776 INFO] Loading dataset from data/asl.train.0.pt\n",
            "[2023-11-18 12:55:37,268 INFO] number of examples: 82706\n",
            "[2023-11-18 12:55:46,785 INFO] Step 1250/100000; acc:  80.07; ppl:  3.76; xent: 1.32; lr: 0.00006; 3004/2907 tok/s;    735 sec\n",
            "[2023-11-18 12:56:13,081 INFO] Step 1300/100000; acc:  76.52; ppl:  4.21; xent: 1.44; lr: 0.00006; 5012/4844 tok/s;    761 sec\n",
            "[2023-11-18 12:56:13,144 INFO] Saving checkpoint model_asl_step_1300.pt\n",
            "[2023-11-18 12:56:43,814 INFO] Step 1350/100000; acc:  81.04; ppl:  3.39; xent: 1.22; lr: 0.00007; 4286/4213 tok/s;    792 sec\n",
            "[2023-11-18 12:57:09,677 INFO] Step 1400/100000; acc:  80.90; ppl:  3.46; xent: 1.24; lr: 0.00007; 5117/4975 tok/s;    818 sec\n",
            "[2023-11-18 12:57:09,796 INFO] Saving checkpoint model_asl_step_1400.pt\n",
            "[2023-11-18 12:57:36,984 INFO] Step 1450/100000; acc:  80.97; ppl:  3.36; xent: 1.21; lr: 0.00007; 4859/4668 tok/s;    845 sec\n",
            "[2023-11-18 12:58:03,747 INFO] Step 1500/100000; acc:  80.85; ppl:  3.38; xent: 1.22; lr: 0.00007; 4962/4824 tok/s;    872 sec\n",
            "[2023-11-18 12:58:03,748 INFO] Loading dataset from data/asl.valid.0.pt\n",
            "[2023-11-18 12:58:04,114 INFO] number of examples: 4000\n",
            "[2023-11-18 12:58:07,109 INFO] Validation perplexity: 3.1187\n",
            "[2023-11-18 12:58:07,109 INFO] Validation accuracy: 82.156\n",
            "[2023-11-18 12:58:07,109 INFO] Model is improving ppl: 4.27118 --> 3.1187.\n",
            "[2023-11-18 12:58:07,109 INFO] Model is improving acc: 76.4157 --> 82.156.\n",
            "[2023-11-18 12:58:07,172 INFO] Saving checkpoint model_asl_step_1500.pt\n",
            "[2023-11-18 12:58:35,665 INFO] Step 1550/100000; acc:  82.40; ppl:  3.07; xent: 1.12; lr: 0.00008; 4115/4028 tok/s;    904 sec\n",
            "[2023-11-18 12:59:00,421 INFO] Step 1600/100000; acc:  81.49; ppl:  3.18; xent: 1.16; lr: 0.00008; 5323/5160 tok/s;    928 sec\n",
            "[2023-11-18 12:59:00,540 INFO] Saving checkpoint model_asl_step_1600.pt\n",
            "[2023-11-18 12:59:25,815 INFO] Loading dataset from data/asl.train.0.pt\n",
            "[2023-11-18 12:59:39,926 INFO] number of examples: 82706\n",
            "[2023-11-18 12:59:44,035 INFO] Step 1650/100000; acc:  82.95; ppl:  3.02; xent: 1.10; lr: 0.00008; 3031/2925 tok/s;    972 sec\n",
            "[2023-11-18 13:00:10,780 INFO] Step 1700/100000; acc:  80.55; ppl:  3.28; xent: 1.19; lr: 0.00008; 4929/4784 tok/s;    999 sec\n",
            "[2023-11-18 13:00:10,849 INFO] Saving checkpoint model_asl_step_1700.pt\n",
            "[2023-11-18 13:00:38,473 INFO] Step 1750/100000; acc:  83.34; ppl:  2.84; xent: 1.04; lr: 0.00009; 4765/4627 tok/s;   1026 sec\n",
            "[2023-11-18 13:01:04,793 INFO] Step 1800/100000; acc:  85.12; ppl:  2.62; xent: 0.96; lr: 0.00009; 5009/4935 tok/s;   1053 sec\n",
            "[2023-11-18 13:01:04,853 INFO] Saving checkpoint model_asl_step_1800.pt\n",
            "[2023-11-18 13:01:33,658 INFO] Step 1850/100000; acc:  82.50; ppl:  2.98; xent: 1.09; lr: 0.00009; 4596/4407 tok/s;   1082 sec\n",
            "[2023-11-18 13:01:59,313 INFO] Step 1900/100000; acc:  84.42; ppl:  2.68; xent: 0.98; lr: 0.00009; 5184/5045 tok/s;   1107 sec\n",
            "[2023-11-18 13:01:59,427 INFO] Saving checkpoint model_asl_step_1900.pt\n",
            "[2023-11-18 13:02:27,339 INFO] Step 1950/100000; acc:  84.77; ppl:  2.56; xent: 0.94; lr: 0.00010; 4685/4589 tok/s;   1135 sec\n",
            "[2023-11-18 13:02:53,537 INFO] Step 2000/100000; acc:  82.76; ppl:  2.74; xent: 1.01; lr: 0.00010; 5026/4844 tok/s;   1161 sec\n",
            "[2023-11-18 13:02:53,538 INFO] Loading dataset from data/asl.valid.0.pt\n",
            "[2023-11-18 13:02:53,923 INFO] number of examples: 4000\n",
            "[2023-11-18 13:02:56,913 INFO] Validation perplexity: 2.93397\n",
            "[2023-11-18 13:02:56,913 INFO] Validation accuracy: 81.3897\n",
            "[2023-11-18 13:02:56,914 INFO] Stalled patience: 2/3\n",
            "[2023-11-18 13:02:56,971 INFO] Saving checkpoint model_asl_step_2000.pt\n",
            "[2023-11-18 13:03:25,739 INFO] Step 2050/100000; acc:  84.05; ppl:  2.65; xent: 0.97; lr: 0.00010; 4127/3964 tok/s;   1194 sec\n",
            "[2023-11-18 13:03:28,062 INFO] Loading dataset from data/asl.train.0.pt\n",
            "[2023-11-18 13:03:43,323 INFO] number of examples: 82706\n",
            "[2023-11-18 13:04:07,711 INFO] Step 2100/100000; acc:  85.94; ppl:  2.40; xent: 0.88; lr: 0.00010; 3133/3048 tok/s;   1236 sec\n",
            "[2023-11-18 13:04:07,827 INFO] Saving checkpoint model_asl_step_2100.pt\n",
            "[2023-11-18 13:04:35,954 INFO] Step 2150/100000; acc:  86.72; ppl:  2.27; xent: 0.82; lr: 0.00010; 4652/4538 tok/s;   1264 sec\n",
            "[2023-11-18 13:05:02,904 INFO] Step 2200/100000; acc:  88.16; ppl:  2.10; xent: 0.74; lr: 0.00009; 4907/4841 tok/s;   1291 sec\n",
            "[2023-11-18 13:05:02,966 INFO] Saving checkpoint model_asl_step_2200.pt\n",
            "[2023-11-18 13:05:31,396 INFO] Step 2250/100000; acc:  86.49; ppl:  2.31; xent: 0.84; lr: 0.00009; 4658/4480 tok/s;   1319 sec\n",
            "[2023-11-18 13:05:56,845 INFO] Step 2300/100000; acc:  87.76; ppl:  2.12; xent: 0.75; lr: 0.00009; 5211/5043 tok/s;   1345 sec\n",
            "[2023-11-18 13:05:56,904 INFO] Saving checkpoint model_asl_step_2300.pt\n",
            "[2023-11-18 13:06:25,772 INFO] Step 2350/100000; acc:  87.98; ppl:  2.07; xent: 0.73; lr: 0.00009; 4559/4446 tok/s;   1374 sec\n",
            "[2023-11-18 13:06:51,542 INFO] Step 2400/100000; acc:  89.09; ppl:  1.95; xent: 0.67; lr: 0.00009; 5097/4945 tok/s;   1399 sec\n",
            "[2023-11-18 13:06:51,660 INFO] Saving checkpoint model_asl_step_2400.pt\n",
            "[2023-11-18 13:07:19,263 INFO] Step 2450/100000; acc:  88.87; ppl:  1.97; xent: 0.68; lr: 0.00009; 4802/4624 tok/s;   1427 sec\n",
            "[2023-11-18 13:07:28,097 INFO] Loading dataset from data/asl.train.0.pt\n",
            "[2023-11-18 13:07:43,735 INFO] number of examples: 82706\n",
            "[2023-11-18 13:08:02,496 INFO] Step 2500/100000; acc:  89.02; ppl:  1.98; xent: 0.68; lr: 0.00009; 3034/2933 tok/s;   1470 sec\n",
            "[2023-11-18 13:08:02,498 INFO] Loading dataset from data/asl.valid.0.pt\n",
            "[2023-11-18 13:08:02,880 INFO] number of examples: 4000\n",
            "[2023-11-18 13:08:06,228 INFO] Validation perplexity: 1.93305\n",
            "[2023-11-18 13:08:06,228 INFO] Validation accuracy: 89.1821\n",
            "[2023-11-18 13:08:06,228 INFO] Model is improving ppl: 3.1187 --> 1.93305.\n",
            "[2023-11-18 13:08:06,228 INFO] Model is improving acc: 82.156 --> 89.1821.\n",
            "[2023-11-18 13:08:06,291 INFO] Saving checkpoint model_asl_step_2500.pt\n",
            "[2023-11-18 13:08:34,983 INFO] Step 2550/100000; acc:  89.60; ppl:  1.88; xent: 0.63; lr: 0.00009; 4066/3967 tok/s;   1503 sec\n",
            "[2023-11-18 13:09:01,530 INFO] Step 2600/100000; acc:  90.67; ppl:  1.77; xent: 0.57; lr: 0.00009; 4972/4894 tok/s;   1529 sec\n",
            "[2023-11-18 13:09:01,589 INFO] Saving checkpoint model_asl_step_2600.pt\n",
            "[2023-11-18 13:09:29,929 INFO] Step 2650/100000; acc:  89.83; ppl:  1.89; xent: 0.64; lr: 0.00009; 4660/4522 tok/s;   1558 sec\n",
            "[2023-11-18 13:09:55,870 INFO] Step 2700/100000; acc:  90.09; ppl:  1.79; xent: 0.58; lr: 0.00009; 5112/4940 tok/s;   1584 sec\n",
            "[2023-11-18 13:09:55,929 INFO] Saving checkpoint model_asl_step_2700.pt\n",
            "[2023-11-18 13:10:25,259 INFO] Step 2750/100000; acc:  89.96; ppl:  1.82; xent: 0.60; lr: 0.00008; 4504/4375 tok/s;   1613 sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 translate.py -model model_step_3000.pt -src /content/DS605/English/ASLG_Processed/src-test.txt-output gloss.txt -gpu 0 -replace_unk -beam_size 4"
      ],
      "metadata": {
        "id": "otDwmlBpdROS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}